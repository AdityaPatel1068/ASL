{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string  # Import the string module for alphabet letters\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define constants\n",
    "input_shape = (256, 256, 1)  # Adjust based on your preprocessed image dimensions\n",
    "\n",
    "# Function to build the CNN model\n",
    "def build_cnn_model(num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))  # Adding dropout for regularization\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Function to compile the model\n",
    "def compile_model(model):\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Function to apply data augmentation\n",
    "def apply_data_augmentation(train_dir):\n",
    "    # Extract alphabet letters\n",
    "    alphabet_letters = string.ascii_uppercase\n",
    "    classes = [folder for folder in os.listdir(train_dir) if folder.upper() in alphabet_letters]\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    return train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(input_shape[0], input_shape[1]),\n",
    "        batch_size=32,\n",
    "        color_mode='grayscale',\n",
    "        class_mode='categorical',\n",
    "        classes=classes\n",
    "    )\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, train_generator, epochs=10):\n",
    "    model.fit(train_generator, epochs=epochs)\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, test_generator):\n",
    "    return model.evaluate(test_generator)\n",
    "\n",
    "# Specify the path to the preprocessed training images\n",
    "preprocessed_train_images_folder_path = '/Users/aditya/Desktop/Class/DS675Machine Learning/Project/DATASET/SPLIT/train'\n",
    "\n",
    "# Apply data augmentation\n",
    "train_generator = apply_data_augmentation(preprocessed_train_images_folder_path)\n",
    "\n",
    "# Build the CNN model\n",
    "cnn_model = build_cnn_model(num_classes=len(train_generator.class_indices))\n",
    "\n",
    "# Compile the model\n",
    "compile_model(cnn_model)\n",
    "\n",
    "# Train the model\n",
    "train_model(cnn_model, train_generator, epochs=10)\n",
    "\n",
    "# Specify the path to the test images\n",
    "test_dataset_folder_path = '/Users/aditya/Desktop/Class/DS675Machine Learning/Project/DATASET/SPLIT/test'\n",
    "\n",
    "# Apply data augmentation to the test set\n",
    "test_generator = apply_data_augmentation(test_dataset_folder_path)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "evaluation_result = evaluate_model(cnn_model, test_generator)\n",
    "print(\"Evaluation Result:\", evaluation_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import rembg\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import Image as IPImage, display\n",
    "\n",
    "# Function to capture an image from the default camera, remove the background, and preprocess it\n",
    "def capture_and_preprocess():\n",
    "    # Open the default camera (camera index 0)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Allow the camera to adjust (you may need to adjust the delay based on your camera)\n",
    "    cv2.waitKey(1000)\n",
    "\n",
    "    # Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Release the camera capture\n",
    "    cap.release()\n",
    "\n",
    "    if ret:\n",
    "        # Convert the OpenCV frame to a PIL Image\n",
    "        pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Use rembg to remove the background\n",
    "        with rembg.remove(pil_image) as result:\n",
    "            # Convert the result to an OpenCV format\n",
    "            sign = cv2.cvtColor(np.array(result), cv2.COLOR_RGBA2BGRA)\n",
    "\n",
    "        # Convert the image to grayscale\n",
    "        grayscale_image = cv2.cvtColor(sign, cv2.COLOR_BGRA2GRAY)\n",
    "\n",
    "        # Resize the image to the target size (256x256)\n",
    "        target_size = (256, 256)\n",
    "        resized_image = cv2.resize(grayscale_image, target_size)\n",
    "\n",
    "        # Remove random noise (salt and pepper noise)\n",
    "        noisy_image = Image.fromarray(resized_image)\n",
    "        noisy_image = noisy_image.point(lambda p: p + random.choice([-50, 0, 50]) if random.random() < 0.05 else p)\n",
    "\n",
    "        # Convert the noisy image back to NumPy array\n",
    "        noisy_image_np = np.array(noisy_image)\n",
    "\n",
    "        return frame, noisy_image_np\n",
    "    else:\n",
    "        print(\"Failed to capture an image.\")\n",
    "        return None\n",
    "\n",
    "from gtts import gTTS\n",
    "from IPython.display import Audio\n",
    "from io import BytesIO\n",
    "\n",
    "def text_to_speech(text):\n",
    "    # Create a gTTS object with the desired text\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "\n",
    "    # Save the generated speech to a BytesIO object\n",
    "    audio_stream = BytesIO()\n",
    "    tts.write_to_fp(audio_stream)\n",
    "    audio_stream.seek(0)\n",
    "\n",
    "    # Display the generated audio\n",
    "    return Audio(data=audio_stream.read(), autoplay=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture an image, remove the background, and preprocess it\n",
    "input_image, preprocessed_image = capture_and_preprocess()\n",
    "\n",
    "# Check if the preprocessed image was successfully captured\n",
    "if preprocessed_image is not None:\n",
    "    # Display the input image\n",
    "    display(IPImage(data=cv2.imencode('.png', input_image)[1].tobytes(), format='png'))\n",
    "\n",
    "    # Display the preprocessed image\n",
    "    display(IPImage(data=cv2.imencode('.png', preprocessed_image)[1].tobytes(), format='png'))\n",
    "\n",
    "    print(\"Image captured, background removed, and preprocessed.\")\n",
    "else:\n",
    "    print(\"Image capture failed.\")\n",
    "\n",
    "input_array = np.array(preprocessed_image)\n",
    "\n",
    "# Expand dimensions to match the input shape expected by the model\n",
    "input_array = np.expand_dims(input_array, axis=0)\n",
    "\n",
    "# Make the prediction\n",
    "predictions = cnn_model.predict(input_array)\n",
    "predicted_class_index = np.argmax(predictions)\n",
    "\n",
    "# Map the index to the corresponding class label\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "predicted_class_label = class_labels[predicted_class_index]\n",
    "\n",
    "print(predicted_class_label)\n",
    "\n",
    "text_input = predicted_class_label\n",
    "audio_output = text_to_speech(text_input)\n",
    "\n",
    "audio_output"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
